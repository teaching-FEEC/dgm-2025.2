{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ceb19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "Embedding(3, 2)\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Random scenario setup\n",
    "B = 1       # batch size\n",
    "z_dim = 5      # latent size\n",
    "K = 3          # number of classes\n",
    "e = 2          # embedding dimension\n",
    "img_dim = 6    # fake image flattened size (toy)\n",
    "\n",
    "# Create random z and labels\n",
    "z = torch.randn(B, z_dim)\n",
    "print(z.shape)\n",
    "\n",
    "y = torch.randint(0, K, (B,))\n",
    "\n",
    "# Embedding for classes\n",
    "embedding = nn.Embedding(K, e)\n",
    "print(embedding)\n",
    "y_emb = embedding(y)\n",
    "print(y_emb.shape)\n",
    "\n",
    "# Generator input\n",
    "g_in = torch.cat([z, y_emb], dim=1)\n",
    "print(g_in.shape)\n",
    "# Fake generator (just linear for demo)\n",
    "G = nn.Linear(z_dim + e, img_dim)\n",
    "x_hat = G(g_in)\n",
    "\n",
    "# Flatten real \"images\" (random)\n",
    "x = torch.randn(B, img_dim)\n",
    "x_flat = x.view(B, -1)\n",
    "\n",
    "# Discriminator input\n",
    "d_in = torch.cat([x_flat, y_emb], dim=1)\n",
    "D = nn.Linear(img_dim + e, 1)\n",
    "score = D(d_in)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f80aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator input: torch.Size([2, 3, 224, 224])\n",
      "Generator output: torch.Size([2, 16, 224, 224])\n",
      "Critic output: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.shs_gan.shs_generator import Generator\n",
    "from src.models.shs_gan.shs_discriminator import Critic3D\n",
    "\n",
    "def test_shapes():\n",
    "    gen = Generator()\n",
    "    critic = Critic3D()\n",
    "    \n",
    "    # Test input\n",
    "    x = torch.randn(2, 3, 224, 224)\n",
    "    print(f\"Generator input: {x.shape}\")\n",
    "    \n",
    "\n",
    "    fake_hsi = gen(x)\n",
    "    print(f\"Generator output: {fake_hsi.shape}\")  # Should be [2, 16, 224, 224]\n",
    "    \n",
    "  \n",
    "    score = critic(fake_hsi)\n",
    "    print(f\"Critic output: {score.shape}\")  # Should be [2, 1]\n",
    "    \n",
    "    return fake_hsi, score\n",
    "\n",
    "fake_hsi, score = test_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5297f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import dependencies\n",
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ebdc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONFIG FILE ANALYSIS ===\n",
      "Class path: data_modules.HSIDermoscopyDataModule\n",
      "Image size: 256\n",
      "Batch size: 4\n",
      "Allowed labels: ['melanoma']\n",
      "Data directory: data/hsi_dermoscopy\n",
      "\n",
      "=== FIXED TRANSFORMS ===\n",
      "Replaced interpolation variables with actual values\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "HSIDermoscopyDataModule.__init__() got an unexpected keyword argument 'class_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m init_args = config[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33minit_args\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     40\u001b[39m init_args[\u001b[33m'\u001b[39m\u001b[33mclass_path\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33msrc.data_modules.HSIDermoscopyDataModule\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m datamodule = \u001b[43mHSIDermoscopyDataModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== DATAMODULE CREATED ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatamodule.hparams.task\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: HSIDermoscopyDataModule.__init__() got an unexpected keyword argument 'class_path'"
     ]
    }
   ],
   "source": [
    "# Test the dataset and configuration only\n",
    "\n",
    "# 1. Load and analyze the config file\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "config_path = \"/mnt/datahdd/kris_volume/dgm-2025.2/projects/hyperskin/configs/data/hsi_dermoscopy_synth.yaml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"=== CONFIG FILE ANALYSIS ===\")\n",
    "print(f\"Class path: {config['data']['class_path']}\")\n",
    "print(f\"Image size: {config['data']['init_args']['image_size']}\")\n",
    "print(f\"Batch size: {config['data']['init_args']['batch_size']}\")\n",
    "print(f\"Allowed labels: {config['data']['init_args']['allowed_labels']}\")\n",
    "print(f\"Data directory: {config['data']['init_args']['data_dir']}\")\n",
    "\n",
    "# 2. Fix the interpolation issues in transforms\n",
    "image_size = config['data']['init_args']['image_size']\n",
    "\n",
    "# Replace the interpolation variables with actual values\n",
    "if 'transforms' in config['data']['init_args']:\n",
    "    transforms = config['data']['init_args']['transforms']\n",
    "    for stage in ['train', 'val', 'test']:\n",
    "        if stage in transforms:\n",
    "            for transform in transforms[stage]:\n",
    "                if 'init_args' in transform:\n",
    "                    for key, value in transform['init_args'].items():\n",
    "                        if isinstance(value, str) and '${data.init_args.image_size}' in value:\n",
    "                            transform['init_args'][key] = image_size\n",
    "\n",
    "print(\"\\n=== FIXED TRANSFORMS ===\")\n",
    "print(\"Replaced interpolation variables with actual values\")\n",
    "\n",
    "# 3. Import and setup the data module\n",
    "from src.data_modules.hsi_dermoscopy import HSIDermoscopyDataModule\n",
    "\n",
    "# Use the fixed config directly instead of OmegaConf\n",
    "init_args = config['data']['init_args']\n",
    "init_args['class_path'] = \"src.data_modules.HSIDermoscopyDataModule\"\n",
    "\n",
    "datamodule = HSIDermoscopyDataModule(**init_args)\n",
    "\n",
    "print(\"\\n=== DATAMODULE CREATED ===\")\n",
    "print(f\"Task: {datamodule.hparams.task}\")\n",
    "print(f\"Image size: {datamodule.hparams.image_size}\")\n",
    "print(f\"Batch size: {datamodule.hparams.batch_size}\")\n",
    "\n",
    "# 4. Prepare data (download if needed)\n",
    "print(\"\\n=== PREPARING DATA ===\")\n",
    "datamodule.prepare_data()\n",
    "\n",
    "# 5. Setup for training\n",
    "print(\"\\n=== SETUP DATA SPLITS ===\")\n",
    "datamodule.setup(stage='fit')\n",
    "\n",
    "# 6. Check dataset sizes\n",
    "print(\"\\n=== DATASET SIZES ===\")\n",
    "print(f\"Training samples: {len(datamodule.data_train)}\")\n",
    "print(f\"Validation samples: {len(datamodule.data_val)}\")\n",
    "if hasattr(datamodule, 'data_test'):\n",
    "    print(f\"Test samples: {len(datamodule.data_test)}\")\n",
    "\n",
    "# 7. Test one batch from training loader\n",
    "print(\"\\n=== TESTING ONE BATCH ===\")\n",
    "train_loader = datamodule.train_dataloader()\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "if isinstance(batch, (list, tuple)):\n",
    "    images, labels = batch\n",
    "    print(f\"Batch images shape: {images.shape}\")  # [B, C, H, W]\n",
    "    print(f\"Batch labels shape: {labels.shape}\")\n",
    "    print(f\"Image dtype: {images.dtype}\")\n",
    "    print(f\"Label dtype: {labels.dtype}\")\n",
    "    print(f\"Image value range: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "    print(f\"Labels: {labels}\")\n",
    "else:\n",
    "    print(f\"Unexpected batch format: {type(batch)}\")\n",
    "\n",
    "print(\"\\n=== CONFIGURATION TEST COMPLETE ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyperskin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
