{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJtCtNGove7c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjw169Tj8srH"
   },
   "outputs": [],
   "source": [
    "# %% ----- 1. Setup & Imports -----\n",
    "# This cell imports all necessary libraries.\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os # To check for file existence\n",
    "import math\n",
    "import time\n",
    "import pandas as pd # Used for a nice results summary\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, IntSlider\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIis0KNC_nGy"
   },
   "outputs": [],
   "source": [
    "# %% ----- 2. Data Loading -----\n",
    "# This cell loads the data from your Google Drive.\n",
    "# **PLEASE ADJUST:** Change 'rope_state_action_next_state_mil.npz' to your filename.\n",
    "\n",
    "file_name = './drive/MyDrive/rope_state_action_next_state_mil.npz' # <--- ADJUST THIS FILENAME\n",
    "\n",
    "# IMPORTANT ASSUMPTION about the keys in the .npz file:\n",
    "states_key = 'states'\n",
    "actions_key = 'actions'\n",
    "next_states_key = 'next_states'\n",
    "# --------------------------------------------------\n",
    "\n",
    "print(f\"Attempting to load data from '{file_name}'...\")\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    print(f\"\\nERROR: File '{file_name}' not found.\")\n",
    "    print(\"Please make sure the file is in your Google Drive at the specified path.\")\n",
    "else:\n",
    "    with np.load(file_name) as data:\n",
    "        s = data[states_key]\n",
    "        a = data[actions_key]\n",
    "        s_prime = data[next_states_key]\n",
    "\n",
    "    print(\"Data successfully loaded.\")\n",
    "    print(f\"Shape 'states':      {s.shape}\")\n",
    "    print(f\"Shape 'actions':     {a.shape}\")\n",
    "    print(f\"Shape 'next_states': {s_prime.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6pz6-rG_tzD"
   },
   "outputs": [],
   "source": [
    "# %% ----- 3. Prepare Data (Corrected for Leakage + CoM Normalization) -----\n",
    "# This cell now centers the rope by its Center of Mass (CoM)\n",
    "# BEFORE calculating deltas or scaling.\n",
    "\n",
    "try:\n",
    "    # --- NEW STEP: Center of Mass (CoM) Normalization ---\n",
    "    print(\"Normalizing states by subtracting Center of Mass (CoM)...\")\n",
    "\n",
    "    s_com = s.mean(axis=1, keepdims=True)\n",
    "    s_prime_com = s_prime.mean(axis=1, keepdims=True)\n",
    "\n",
    "    s_norm = s - s_com\n",
    "    s_prime_norm = s_prime - s_prime_com\n",
    "\n",
    "    print(\"CoM normalization complete.\")\n",
    "\n",
    "    # 1. Calculate Target (Delta)\n",
    "    y = s_prime_norm - s_norm\n",
    "\n",
    "    # 2. Define Inputs\n",
    "    X_s = s_norm  # Use the centered state\n",
    "    X_a_force = a[:, :3]\n",
    "    X_a_link_id = a[:, 3].reshape(-1, 1).astype(np.int32)\n",
    "\n",
    "    print(f\"Actions split into 'force' {X_a_force.shape} and 'link_id' {X_a_link_id.shape}\")\n",
    "\n",
    "    num_samples = X_s.shape[0]\n",
    "    num_links = X_s.shape[1]\n",
    "    state_dims = X_s.shape[2]\n",
    "    force_dims = X_a_force.shape[1]\n",
    "\n",
    "    # 3. Train/Validation Split (BEFORE SCALING)\n",
    "    print(\"Creating Train/Validation split...\")\n",
    "    (\n",
    "        X_s_train, X_s_val,\n",
    "        X_a_force_train, X_a_force_val,\n",
    "        X_a_link_id_train, X_a_link_id_val,\n",
    "        y_train, y_val\n",
    "    ) = train_test_split(\n",
    "        X_s,           # Already centered\n",
    "        X_a_force,\n",
    "        X_a_link_id,\n",
    "        y,           # Already centered\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # --- FIX FOR VISUALIZATION CELLS ---\n",
    "    # Save the unscaled, centered validation data before it gets overwritten\n",
    "    X_s_val_unscaled_viz = X_s_val.copy()\n",
    "    y_val_unscaled_viz = y_val.copy()\n",
    "    X_a_force_val_unscaled_viz = X_a_force_val.copy()\n",
    "    X_a_link_id_val_viz = X_a_link_id_val.copy()\n",
    "    # -------------------------------------\n",
    "\n",
    "    # 4. Scale Data (Fit ONLY on Train)\n",
    "    print(\"Scaling data (fitting on training set only)...\")\n",
    "\n",
    "    scaler_s = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    scaler_a_force = StandardScaler()\n",
    "\n",
    "    X_s_train_flat = X_s_train.reshape(-1, state_dims)\n",
    "    X_s_val_flat = X_s_val.reshape(-1, state_dims)\n",
    "    y_train_flat = y_train.reshape(-1, state_dims)\n",
    "    y_val_flat = y_val.reshape(-1, state_dims)\n",
    "\n",
    "    scaler_s.fit(X_s_train_flat)\n",
    "    scaler_y.fit(y_train_flat)\n",
    "    scaler_a_force.fit(X_a_force_train)\n",
    "\n",
    "    X_s_train_scaled_flat = scaler_s.transform(X_s_train_flat)\n",
    "    X_s_val_scaled_flat = scaler_s.transform(X_s_val_flat)\n",
    "\n",
    "    y_train_scaled_flat = scaler_y.transform(y_train_flat)\n",
    "    y_val_scaled_flat = scaler_y.transform(y_val_flat)\n",
    "\n",
    "    X_a_force_train_scaled = scaler_a_force.transform(X_a_force_train)\n",
    "    X_a_force_val_scaled = scaler_a_force.transform(X_a_force_val)\n",
    "\n",
    "    X_s_train_scaled = X_s_train_scaled_flat.reshape(X_s_train.shape)\n",
    "    X_s_val_scaled = X_s_val_scaled_flat.reshape(X_s_val.shape)\n",
    "\n",
    "    y_train_scaled = y_train_scaled_flat.reshape(y_train.shape)\n",
    "    y_val_scaled = y_val_scaled_flat.reshape(y_val.shape)\n",
    "\n",
    "    print(\"Scaling complete.\")\n",
    "\n",
    "    # 5. Create final model inputs (as NumPy arrays)\n",
    "    # We will convert these to Tensors in the training loop\n",
    "    X_train_list = [X_s_train_scaled, X_a_force_train_scaled, X_a_link_id_train]\n",
    "    X_val_list = [X_s_val_scaled, X_a_force_val_scaled, X_a_link_id_val]\n",
    "\n",
    "    y_train_np = y_train_scaled\n",
    "    y_val_np = y_val_scaled\n",
    "\n",
    "    print(f\"Training samples: {len(X_s_train_scaled)}\")\n",
    "    print(f\"Validation samples: {len(X_s_val_scaled)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred during data preparation: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_Vh8ZoO_zix"
   },
   "outputs": [],
   "source": [
    "# %% ----- 4. Model Building (Transformer Encoder) -----\n",
    "# This cell defines the building blocks for a Transformer Encoder\n",
    "# and wraps them in a PyTorch nn.Module.\n",
    "\n",
    "# --- 1. Positional Encoding Layer ---\n",
    "# (Keras-equivalent, without internal dropout)\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, position):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(position, d_model)\n",
    "        pos = torch.arange(0, position, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        pe = pe.unsqueeze(0) # Shape: (1, position, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n",
    "# --- 2. Main `TransformerModel` Module ---\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, hparams, num_links, state_dims, force_dims):\n",
    "        \"\"\"\n",
    "        Builds the Transformer model based on hyperparameters.\n",
    "        \"\"\"\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        # Get hyperparameters\n",
    "        EMBEDDING_DIM = hparams['embedding_dim']\n",
    "        NUM_HEADS = hparams['num_heads']\n",
    "        FF_DIM = hparams['ff_dim']\n",
    "        NUM_BLOCKS = hparams['num_blocks']\n",
    "        DROPOUT_RATE = hparams['dropout']\n",
    "\n",
    "        ACTION_VEC_DIM = force_dims + EMBEDDING_DIM\n",
    "        MODEL_DIM = state_dims + ACTION_VEC_DIM\n",
    "\n",
    "        self.num_links = num_links\n",
    "        self.action_vec_dim = ACTION_VEC_DIM\n",
    "        self.model_dim = MODEL_DIM\n",
    "\n",
    "        if MODEL_DIM % NUM_HEADS != 0:\n",
    "            raise ValueError(f\"MODEL_DIM ({MODEL_DIM}) must be divisible by NUM_HEADS ({NUM_HEADS})\")\n",
    "\n",
    "        # --- Sparse Action Injection Layers ---\n",
    "        self.link_embedding = nn.Embedding(num_links, EMBEDDING_DIM)\n",
    "        # Note: Keras 'Flatten' is handled by using (N) input to Embedding\n",
    "\n",
    "        # --- Transformer Encoder Stack ---\n",
    "        # 1. Positional Encoding (matches Keras implementation)\n",
    "        self.pos_encoder = PositionalEncoding(d_model=MODEL_DIM, position=num_links)\n",
    "        # 2. Input LayerNorm and Dropout (matches Keras pre-stack layers)\n",
    "        self.input_norm = nn.LayerNorm(MODEL_DIM)\n",
    "        self.input_dropout = nn.Dropout(DROPOUT_RATE)\n",
    "\n",
    "        # 3. Transformer Encoder Layers\n",
    "        # nn.TransformerEncoderLayer is batch_first=False by default, but Keras is batch_first=True\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=MODEL_DIM,\n",
    "            nhead=NUM_HEADS,\n",
    "            dim_feedforward=FF_DIM,\n",
    "            dropout=DROPOUT_RATE,\n",
    "            activation='relu',\n",
    "            batch_first=True, # Set batch_first=True to match Keras\n",
    "            norm_first=False  # Use post-norm to match Keras block\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer, \n",
    "            num_layers=NUM_BLOCKS\n",
    "        )\n",
    "\n",
    "        # --- Final Output Layer ---\n",
    "        # Keras TimeDistributed(Dense) is just a Linear layer on each time step\n",
    "        self.output_layer = nn.Linear(MODEL_DIM, state_dims)\n",
    "\n",
    "    def forward(self, state_input, action_force_input, action_link_id_input):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        state_input: (N, 70, 3)\n",
    "        action_force_input: (N, 3)\n",
    "        action_link_id_input: (N) [Note: Keras was (N,1), we use (N) for nn.Embedding]\n",
    "        \"\"\"\n",
    "        \n",
    "        # --- Sparse Action Injection (Same as BiLSTM model) ---\n",
    "        # (N) -> (N, EMBEDDING_DIM)\n",
    "        embedded_link_flat = self.link_embedding(action_link_id_input)\n",
    "        \n",
    "        # (N, 3) + (N, EMBEDDING_DIM) -> (N, ACTION_VEC_DIM)\n",
    "        combined_action_vec = torch.cat([action_force_input, embedded_link_flat], dim=1)\n",
    "        \n",
    "        # (N) -> (N, 70)\n",
    "        action_mask = F.one_hot(action_link_id_input, num_classes=self.num_links).float()\n",
    "\n",
    "        # (N, 70) -> (N, 70, 1)\n",
    "        action_mask_expanded = action_mask.unsqueeze(-1)\n",
    "        # (N, ACTION_VEC_DIM) -> (N, 1, ACTION_VEC_DIM)\n",
    "        combined_action_vec_expanded = combined_action_vec.unsqueeze(1)\n",
    "\n",
    "        # (N, 70, 1) * (N, 1, ACTION_VEC_DIM) -> (N, 70, ACTION_VEC_DIM) via broadcasting\n",
    "        sparse_action_tensor = action_mask_expanded * combined_action_vec_expanded\n",
    "\n",
    "        # (N, 70, 3) + (N, 70, ACTION_VEC_DIM) -> (N, 70, MODEL_DIM)\n",
    "        combined_input = torch.cat([state_input, sparse_action_tensor], dim=-1)\n",
    "\n",
    "        # --- Transformer Encoder Stack ---\n",
    "        # 1. Add Positional Encoding\n",
    "        x = self.pos_encoder(combined_input)\n",
    "        # 2. Apply pre-stack Norm and Dropout (as in Keras code)\n",
    "        x = self.input_norm(x)\n",
    "        x = self.input_dropout(x)\n",
    "        # 3. Build Encoder Layers\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # --- Final Output Layer ---\n",
    "        # (N, 70, MODEL_DIM) -> (N, 70, 3)\n",
    "        output_delta = self.output_layer(x)\n",
    "\n",
    "        return output_delta\n",
    "\n",
    "print(\"Cell 4: PyTorch Transformer model-building components are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvMBDNEb_44g"
   },
   "outputs": [],
   "source": [
    "# %% ----- 5. Hyperparameter Tuning Loop (Refined Search) -----\n",
    "\n",
    "# --- 1. Define Hyperparameter Sets ---\n",
    "hyperparameter_sets = [\n",
    "    {\n",
    "        'name': 'X-Large (Wider)',\n",
    "        'embedding_dim': 122, # MODEL_DIM = 128\n",
    "        'num_heads': 8,       # (128 % 8 == 0)\n",
    "        'ff_dim': 512,      # (e.g., 4 * 128)\n",
    "        'num_blocks': 6,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 1e-3,\n",
    "        'batch_size': 128\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- 2. Training Loop ---\n",
    "results = []\n",
    "best_overall_loss = float('inf')\n",
    "best_model_state = None\n",
    "best_model_name = \"None\"\n",
    "best_history = None\n",
    "\n",
    "print(f\"Starting REFINED Transformer search across {len(hyperparameter_sets)} models.\")\n",
    "\n",
    "for hparams in hyperparameter_sets:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"STARTING RUN: {hparams['name']}\")\n",
    "    print(f\"Params: {hparams}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # --- Create Datasets and DataLoaders ---\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(X_train_list[0], dtype=torch.float32),\n",
    "        torch.tensor(X_train_list[1], dtype=torch.float32),\n",
    "        torch.tensor(X_train_list[2], dtype=torch.long).squeeze(-1), # Squeeze for nn.Embedding\n",
    "        torch.tensor(y_train_np, dtype=torch.float32)\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.tensor(X_val_list[0], dtype=torch.float32),\n",
    "        torch.tensor(X_val_list[1], dtype=torch.float32),\n",
    "        torch.tensor(X_val_list[2], dtype=torch.long).squeeze(-1),\n",
    "        torch.tensor(y_val_np, dtype=torch.float32)\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=hparams['batch_size'], \n",
    "        shuffle=True, \n",
    "        num_workers=2, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=hparams['batch_size'], \n",
    "        shuffle=False, \n",
    "        num_workers=2, \n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # --- Initialize Model and Optimizer ---\n",
    "    current_model = TransformerModel(hparams, num_links, state_dims, force_dims).to(device)\n",
    "    \n",
    "    # Print model summary (simple version)\n",
    "    total_params = sum(p.numel() for p in current_model.parameters() if p.requires_grad)\n",
    "    print(f\"Model '{hparams['name']}' created with {total_params:,} trainable parameters.\")\n",
    "    # print(current_model) # Uncomment for detailed architecture\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(current_model.parameters(), lr=hparams['learning_rate'])\n",
    "    \n",
    "    # Callbacks\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        'min', \n",
    "        factor=0.2, \n",
    "        patience=3, \n",
    "        min_lr=1e-6, \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Manual EarlyStopping parameters\n",
    "    early_stop_patience = 10\n",
    "    epochs_no_improve = 0\n",
    "    best_epoch_loss = float('inf')\n",
    "    run_history = {'loss': [], 'val_loss': []}\n",
    "    best_model_state_this_run = None\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Training Epoch Loop ---\n",
    "    for epoch in range(100): # Keras was 100 epochs\n",
    "        current_model.train()\n",
    "        train_loss = 0.0\n",
    "        for s_batch, f_batch, l_batch, y_batch in train_loader:\n",
    "            s_batch = s_batch.to(device)\n",
    "            f_batch = f_batch.to(device)\n",
    "            l_batch = l_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = current_model(s_batch, f_batch, l_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * s_batch.size(0)\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        run_history['loss'].append(avg_train_loss)\n",
    "\n",
    "        # --- Validation Loop ---\n",
    "        current_model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for s_batch, f_batch, l_batch, y_batch in val_loader:\n",
    "                s_batch = s_batch.to(device)\n",
    "                f_batch = f_batch.to(device)\n",
    "                l_batch = l_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                \n",
    "                outputs = current_model(s_batch, f_batch, l_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item() * s_batch.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        run_history['val_loss'].append(avg_val_loss)\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/100 - loss: {avg_train_loss:.6f} - val_loss: {avg_val_loss:.6f} - lr: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "        # --- Early Stopping Logic ---\n",
    "        if avg_val_loss < best_epoch_loss:\n",
    "            best_epoch_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Save the best model state\n",
    "            best_model_state_this_run = current_model.state_dict()\n",
    "            print(f\"  New best validation loss: {best_epoch_loss:.6f}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch + 1} epochs.\")\n",
    "            print(f\"Restoring model weights from the best epoch (loss: {best_epoch_loss:.6f}).\")\n",
    "            current_model.load_state_dict(best_model_state_this_run)\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # --- 3. Store Results ---\n",
    "    results.append({\n",
    "        'name': hparams['name'],\n",
    "        'best_val_loss': best_epoch_loss,\n",
    "        'epochs_run': len(run_history['val_loss']),\n",
    "        'training_time_sec': end_time - start_time,\n",
    "        'history': run_history\n",
    "    })\n",
    "\n",
    "    # --- 4. Keep the Best Model ---\n",
    "    if best_epoch_loss < best_overall_loss:\n",
    "        print(f\"\\nNew best overall model found! Loss: {best_epoch_loss:.6f}\")\n",
    "        best_overall_loss = best_epoch_loss\n",
    "        best_model_state = best_model_state_this_run\n",
    "        best_model_name = hparams['name']\n",
    "        best_history = run_history\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Hyperparameter Tuning Complete\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Display a summary table\n",
    "results_df = pd.DataFrame(results).drop('history', axis=1)\n",
    "print(results_df.sort_values(by='best_val_loss').to_markdown(index=False))\n",
    "\n",
    "print(f\"\\nBest model: '{best_model_name}' (Loss: {best_overall_loss:.6f})\")\n",
    "print(\"This model is now stored in the 'model' variable for visualization.\")\n",
    "\n",
    "# --- 5. Finalize the best model ---\n",
    "# Create a new model instance with the best hparams and load the state dict\n",
    "best_hparams = next(h for h in hyperparameter_sets if h['name'] == best_model_name)\n",
    "model = TransformerModel(best_hparams, num_links, state_dims, force_dims).to(device)\n",
    "model.load_state_dict(best_model_state)\n",
    "history = best_history # for the next cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74j8S1bq_71t"
   },
   "outputs": [],
   "source": [
    "# %% ----- 6. Visualize Training History (Loss) -----\n",
    "\n",
    "print(\"\\nVisualizing Training History (Loss)...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss vs. Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error (Scaled)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpxjEuzr_-Hq"
   },
   "outputs": [],
   "source": [
    "# %% ----- 7. Prediction & Visualization (2D - 10 Samples) -----\n",
    "# This version selects 10 random samples and plots them\n",
    "# in a 2x5 grid.\n",
    "\n",
    "print(\"\\nCreating 10 sample predictions...\")\n",
    "\n",
    "num_samples_to_plot = 10\n",
    "\n",
    "if len(X_s_val_scaled) < num_samples_to_plot:\n",
    "    print(f\"Warning: Only {len(X_s_val_scaled)} samples in validation set. Using all.\")\n",
    "    num_samples_to_plot = len(X_s_val_scaled)\n",
    "    sample_indices = np.arange(num_samples_to_plot)\n",
    "else:\n",
    "    sample_indices = np.random.choice(len(X_s_val_scaled), num_samples_to_plot, replace=False)\n",
    "\n",
    "# Get the scaled input data (batch of 10)\n",
    "s_batch_scaled = X_s_val_scaled[sample_indices]\n",
    "a_force_batch_scaled = X_a_force_val_scaled[sample_indices]\n",
    "a_link_id_batch = X_a_link_id_val[sample_indices]\n",
    "y_true_batch_scaled = y_val_scaled[sample_indices]\n",
    "\n",
    "# --- PyTorch Prediction ---\n",
    "model.eval() # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    s_tensor = torch.tensor(s_batch_scaled, dtype=torch.float32).to(device)\n",
    "    f_tensor = torch.tensor(a_force_batch_scaled, dtype=torch.float32).to(device)\n",
    "    l_tensor = torch.tensor(a_link_id_batch, dtype=torch.long).squeeze(-1).to(device)\n",
    "    \n",
    "    delta_pred_batch_scaled_tensor = model(s_tensor, f_tensor, l_tensor)\n",
    "    delta_pred_batch_scaled = delta_pred_batch_scaled_tensor.cpu().numpy()\n",
    "# ------------------------\n",
    "\n",
    "# --- Inverse Transform (Un-scaling) ---\n",
    "s_batch_flat = s_batch_scaled.reshape(-1, state_dims)\n",
    "y_true_batch_flat = y_true_batch_scaled.reshape(-1, state_dims)\n",
    "delta_pred_batch_flat = delta_pred_batch_scaled.reshape(-1, state_dims)\n",
    "\n",
    "all_s_original_flat = scaler_s.inverse_transform(s_batch_flat)\n",
    "all_y_true_unscaled_flat = scaler_y.inverse_transform(y_true_batch_flat)\n",
    "all_delta_pred_unscaled_flat = scaler_y.inverse_transform(delta_pred_batch_flat)\n",
    "\n",
    "all_a_force_original = scaler_a_force.inverse_transform(a_force_batch_scaled)\n",
    "all_a_link_id_original = a_link_id_batch.squeeze() # Shape (10,)\n",
    "\n",
    "# Reshape back to (10, 70, 3)\n",
    "all_s_original = all_s_original_flat.reshape(num_samples_to_plot, num_links, state_dims)\n",
    "all_y_true_unscaled = all_y_true_unscaled_flat.reshape(num_samples_to_plot, num_links, state_dims)\n",
    "all_delta_pred_unscaled = all_delta_pred_unscaled_flat.reshape(num_samples_to_plot, num_links, state_dims)\n",
    "\n",
    "# --- Calculate Final States ---\n",
    "all_next_state_true = all_s_original + all_y_true_unscaled\n",
    "all_next_state_pred = all_s_original + all_delta_pred_unscaled\n",
    "\n",
    "# --- 2D Plot Grid (Code is identical to Keras version) ---\n",
    "print(\"Visualizing 10 random rope predictions in 2D...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(25, 10)) # 2 rows, 5 columns\n",
    "\n",
    "def plot_rope_2d(ax, rope_coords, label, color, style='-o'):\n",
    "    x = rope_coords[:, 0]\n",
    "    y = rope_coords[:, 1]\n",
    "    ax.plot(x, y, style, label=label, color=color, markersize=3, lw=2)\n",
    "\n",
    "typical_force_magnitude = np.linalg.norm(scaler_a_force.scale_)\n",
    "if typical_force_magnitude < 1e-6:\n",
    "    typical_force_magnitude = 1.0 \n",
    "\n",
    "for i in range(num_samples_to_plot):\n",
    "    ax = axes.flat[i]\n",
    "    s_original = all_s_original[i]\n",
    "    next_state_true = all_next_state_true[i]\n",
    "    next_state_pred = all_next_state_pred[i]\n",
    "    a_force_original = all_a_force_original[i]\n",
    "    a_link_id_original = all_a_link_id_original[i]\n",
    "\n",
    "    all_coords = np.concatenate([s_original, next_state_true, next_state_pred], axis=0)\n",
    "    min_vals = all_coords.min(axis=0)\n",
    "    max_vals = all_coords.max(axis=0)\n",
    "\n",
    "    scene_range_2d = np.linalg.norm(max_vals[:2] - min_vals[:2])\n",
    "    base_arrow_length = scene_range_2d * 0.2 \n",
    "    force_to_visual_scale = base_arrow_length / typical_force_magnitude\n",
    "\n",
    "    plot_rope_2d(ax, s_original, 'Initial State', 'gray', style='--')\n",
    "    plot_rope_2d(ax, next_state_true, 'True Next State', 'blue')\n",
    "    plot_rope_2d(ax, next_state_pred, 'Predicted Next State', 'red')\n",
    "\n",
    "    start_point = s_original[a_link_id_original]\n",
    "    U_vec = a_force_original[0] * force_to_visual_scale\n",
    "    V_vec = a_force_original[1] * force_to_visual_scale\n",
    "\n",
    "    ax.quiver(\n",
    "        start_point[0], start_point[1], U_vec, V_vec,\n",
    "        color='magenta', label=f'Force (Link {a_link_id_original})',\n",
    "        scale=1, scale_units='xy', angles='xy', zorder=5\n",
    "    )\n",
    "    ax.scatter(\n",
    "        start_point[0], start_point[1], color='magenta',\n",
    "        s=50, edgecolors='black', alpha=0.8, zorder=10\n",
    "    )\n",
    "\n",
    "    final_mse = np.mean((next_state_true - next_state_pred)**2)\n",
    "    ax.set_title(f'Sample (Val Idx: {sample_indices[i]})\\nMSE: {final_mse:.6f}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.grid(True)\n",
    "    ax.axis('equal')\n",
    "    ax.set_xlim([min_vals[0], max_vals[0]])\n",
    "    ax.set_ylim([min_vals[1], max_vals[1]])\n",
    "\n",
    "axes.flat[0].legend(loc='best', fontsize='small')\n",
    "\n",
    "for j in range(num_samples_to_plot, 10):\n",
    "    axes.flat[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TyIZ0BALC88"
   },
   "outputs": [],
   "source": [
    "# %% ----- 8. Interactive Trajectory Viewer (2D, Fixed Scale, Corrected) -----\n",
    "\n",
    "print(\"Preparing 100 random samples for 2D visualization...\")\n",
    "\n",
    "# --- (Data selection, prediction, and un-scaling) ---\n",
    "num_viz_samples = 100\n",
    "if len(X_s_val_scaled) < num_viz_samples:\n",
    "    num_viz_samples = len(X_s_val_scaled)\n",
    "viz_indices = np.random.choice(len(X_s_val_scaled), num_viz_samples, replace=False)\n",
    "\n",
    "s_batch_scaled = X_s_val_scaled[viz_indices]\n",
    "a_force_batch_scaled = X_a_force_val_scaled[viz_indices]\n",
    "a_link_id_batch = X_a_link_id_val[viz_indices]\n",
    "y_true_batch_scaled = y_val_scaled[viz_indices]\n",
    "\n",
    "# --- PyTorch Prediction ---\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    s_tensor = torch.tensor(s_batch_scaled, dtype=torch.float32).to(device)\n",
    "    f_tensor = torch.tensor(a_force_batch_scaled, dtype=torch.float32).to(device)\n",
    "    l_tensor = torch.tensor(a_link_id_batch, dtype=torch.long).squeeze(-1).to(device)\n",
    "    \n",
    "    delta_pred_batch_scaled_tensor = model(s_tensor, f_tensor, l_tensor)\n",
    "    delta_pred_batch_scaled = delta_pred_batch_scaled_tensor.cpu().numpy()\n",
    "# ------------------------\n",
    "\n",
    "s_batch_flat = s_batch_scaled.reshape(-1, state_dims)\n",
    "y_true_batch_flat = y_true_batch_scaled.reshape(-1, state_dims)\n",
    "delta_pred_batch_flat = delta_pred_batch_scaled.reshape(-1, state_dims)\n",
    "\n",
    "s_original_flat = scaler_s.inverse_transform(s_batch_flat)\n",
    "y_true_unscaled_flat = scaler_y.inverse_transform(y_true_batch_flat)\n",
    "delta_pred_unscaled_flat = scaler_y.inverse_transform(delta_pred_batch_flat)\n",
    "\n",
    "all_s_original = s_original_flat.reshape(num_viz_samples, num_links, state_dims)\n",
    "all_y_true_unscaled = y_true_unscaled_flat.reshape(num_viz_samples, num_links, state_dims)\n",
    "all_delta_pred_unscaled = delta_pred_unscaled_flat.reshape(num_viz_samples, num_links, state_dims)\n",
    "\n",
    "a_force_original_batch = scaler_a_force.inverse_transform(a_force_batch_scaled)\n",
    "a_link_id_original_batch = a_link_id_batch.squeeze()\n",
    "\n",
    "all_next_state_true = all_s_original + all_y_true_unscaled\n",
    "all_next_state_pred = all_s_original + all_delta_pred_unscaled\n",
    "# --- (End of data prep) ---\n",
    "\n",
    "# --- 4. Calculate Global 2D Plot Boundaries (Identical to Keras) ---\n",
    "print(\"Calculating global 2D plot boundaries for fixed scale...\")\n",
    "global_all_coords = np.concatenate([all_s_original, all_next_state_true, all_next_state_pred], axis=0)\n",
    "global_min_vals_2d = global_all_coords.reshape(-1, 3)[:, :2].min(axis=0)\n",
    "global_max_vals_2d = global_all_coords.reshape(-1, 3)[:, :2].max(axis=0)\n",
    "global_scene_range = np.linalg.norm(global_max_vals_2d - global_min_vals_2d)\n",
    "GLOBAL_ARROW_LENGTH = max(global_scene_range * 0.15, 0.1)\n",
    "print(\"Global boundaries calculated. Ready to plot.\")\n",
    "\n",
    "# --- 5. Define Helper and Plotting Functions (2D) (Identical to Keras) ---\n",
    "def plot_rope_2d(ax, rope_coords, label, color, style='-o'):\n",
    "    x = rope_coords[:, 0]\n",
    "    y = rope_coords[:, 1]\n",
    "    ax.plot(x, y, style, label=label, color=color, markersize=3)\n",
    "\n",
    "def plot_prediction_2d(index):\n",
    "    s_original = all_s_original[index]\n",
    "    next_state_true = all_next_state_true[index]\n",
    "    next_state_pred = all_next_state_pred[index]\n",
    "    a_force = a_force_original_batch[index]\n",
    "    link_id = a_link_id_original_batch[index]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    plot_rope_2d(ax, s_original, 'Initial State', 'gray', style='--')\n",
    "    plot_rope_2d(ax, next_state_true, 'True Next State', 'blue')\n",
    "    plot_rope_2d(ax, next_state_pred, 'Predicted Next State', 'red')\n",
    "\n",
    "    start_point = s_original[link_id]\n",
    "    force_norm = np.linalg.norm(a_force)\n",
    "    normalized_force = a_force / force_norm if force_norm > 1e-6 else np.array([0,0,0])\n",
    "\n",
    "    U_vec = normalized_force[0] * GLOBAL_ARROW_LENGTH\n",
    "    V_vec = normalized_force[1] * GLOBAL_ARROW_LENGTH\n",
    "\n",
    "    ax.quiver(\n",
    "        start_point[0], start_point[1],\n",
    "        U_vec, V_vec,\n",
    "        color='magenta',\n",
    "        label=f'Force Vector (at Link {link_id})',\n",
    "        scale=1,\n",
    "        scale_units='xy',\n",
    "        angles='xy'\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        start_point[0], start_point[1],\n",
    "        color='magenta', s=100, label=f'Action at Link {link_id}',\n",
    "        edgecolors='black', alpha=0.8, zorder=10\n",
    "    )\n",
    "\n",
    "    final_mse = np.mean((next_state_true - next_state_pred)**2)\n",
    "    ax.set_title(f'Sample Index: {index} (Link: {link_id}, MSE: {final_mse:.6f})')\n",
    "    ax.set_xlabel('X Coordinate')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    ax.axis('equal')\n",
    "\n",
    "    ax.set_xlim([global_min_vals_2d[0], global_max_vals_2d[0]])\n",
    "    ax.set_ylim([global_min_vals_2d[1], global_max_vals_2d[1]])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# --- 6. Create and Display the Interactive Slider ---\n",
    "print(\"\\nDisplaying interactive 2D slider. (Fixed scale, continuous update)\")\n",
    "interact(\n",
    "    plot_prediction_2d,\n",
    "    index=IntSlider(\n",
    "        min=0,\n",
    "        max=num_viz_samples - 1,\n",
    "        step=1,\n",
    "        value=0,\n",
    "        description='Sample Index:',\n",
    "        continuous_update=True\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lMGEXLUNupz"
   },
   "outputs": [],
   "source": [
    "# %% ----- 9. Trajectory Animation (2D Version - FIXED) -----\n",
    "# This version is fixed to accept the correct unscaled data variables\n",
    "# saved in Cell 4.\n",
    "\n",
    "def animate_trajectory_pytorch_2d(\n",
    "    model, \n",
    "    X_val_list_scaled,       # List of [s, a_f, a_l] (scaled)\n",
    "    s_val_unscaled,          # Numpy array of s (unscaled, centered)\n",
    "    y_val_unscaled,          # Numpy array of y_delta (unscaled, centered)\n",
    "    scaler_y,                # The fitted scaler for deltas\n",
    "    start_idx=0, \n",
    "    steps=50, \n",
    "    interval=100,\n",
    "    save=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Live 2D animation of predicted vs real rope states for a PyTorch model.\n",
    "    \"\"\"\n",
    "    print(\"Preparing 2D animation data...\")\n",
    "\n",
    "    if start_idx + steps > len(s_val_unscaled):\n",
    "        print(f\"Warning: Not enough data. Reducing steps to {len(s_val_unscaled) - start_idx}\")\n",
    "        steps = len(s_val_unscaled) - start_idx\n",
    "\n",
    "    # --- 1. Get data for the animation frames ---\n",
    "    indices = range(start_idx, start_idx + steps)\n",
    "    \n",
    "    # Get scaled inputs for prediction\n",
    "    s_in_scaled = X_val_list_scaled[0][indices]\n",
    "    a_force_in_scaled = X_val_list_scaled[1][indices]\n",
    "    a_link_in = X_val_list_scaled[2][indices]\n",
    "    \n",
    "    # Get unscaled originals for plotting\n",
    "    all_s_orig = s_val_unscaled[indices]\n",
    "    all_y_true = y_val_unscaled[indices]\n",
    "\n",
    "    # --- 2. Predict scaled deltas ---\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        s_tensor = torch.tensor(s_in_scaled, dtype=torch.float32).to(device)\n",
    "        f_tensor = torch.tensor(a_force_in_scaled, dtype=torch.float32).to(device)\n",
    "        l_tensor = torch.tensor(a_link_in, dtype=torch.long).squeeze(-1).to(device)\n",
    "        \n",
    "        all_delta_pred_scaled_tensor = model(s_tensor, f_tensor, l_tensor)\n",
    "        all_delta_pred_scaled = all_delta_pred_scaled_tensor.cpu().numpy()\n",
    "\n",
    "    # --- 3. Un-scale the predicted deltas ---\n",
    "    all_delta_pred_scaled_flat = all_delta_pred_scaled.reshape(-1, state_dims)\n",
    "    all_delta_pred_unscaled_flat = scaler_y.inverse_transform(all_delta_pred_scaled_flat)\n",
    "    all_delta_pred_unscaled = all_delta_pred_unscaled_flat.reshape(steps, num_links, state_dims)\n",
    "\n",
    "    # --- 4. Calculate final states ---\n",
    "    all_s_next_pred = all_s_orig + all_delta_pred_unscaled\n",
    "    all_s_next_true = all_s_orig + all_y_true\n",
    "    # --- (End of data prep) ---\n",
    "\n",
    "    # --- 5. Setup the 2D plot (Matplotlib code is identical) ---\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    real_line, = ax.plot([], [], 'o-', color='blue', label='Real')\n",
    "    pred_line, = ax.plot([], [], 'o--', color='red', label='Predicted')\n",
    "    init_line, = ax.plot([], [], 'o-', color='gray', alpha=0.3, label='Initial State')\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.grid(True)\n",
    "    ax.axis('equal')\n",
    "\n",
    "    # --- 6. Set fixed 2D plot limits ---\n",
    "    global_all_coords = np.concatenate([all_s_orig, all_s_next_true, all_s_next_pred], axis=0)\n",
    "    global_min_vals_2d = global_all_coords.reshape(-1, 3)[:, :2].min(axis=0)\n",
    "    global_max_vals_2d = global_all_coords.reshape(-1, 3)[:, :2].max(axis=0)\n",
    "\n",
    "    ax.set_xlim([global_min_vals_2d[0], global_max_vals_2d[0]])\n",
    "    ax.set_ylim([global_min_vals_2d[1], global_max_vals_2d[1]])\n",
    "\n",
    "    def init():\n",
    "        real_line.set_data([], [])\n",
    "        pred_line.set_data([], [])\n",
    "        init_line.set_data([], [])\n",
    "        return real_line, pred_line, init_line\n",
    "\n",
    "    def update(frame):\n",
    "        s_orig = all_s_orig[frame]\n",
    "        s_next_true = all_s_next_true[frame]\n",
    "        s_next_pred = all_s_next_pred[frame]\n",
    "\n",
    "        init_line.set_data(s_orig[:, 0], s_orig[:, 1])\n",
    "        real_line.set_data(s_next_true[:, 0], s_next_true[:, 1])\n",
    "        pred_line.set_data(s_next_pred[:, 0], s_next_pred[:, 1])\n",
    "\n",
    "        ax.set_title(f\"Frame {start_idx + frame}\")\n",
    "        return real_line, pred_line, init_line\n",
    "\n",
    "    ani = FuncAnimation(\n",
    "        fig, update, frames=steps, init_func=init,\n",
    "        blit=False, interval=interval, repeat=False,\n",
    "    )\n",
    "\n",
    "    if save:\n",
    "        save_path = 'rope_animation_pytorch_2d.mp4'\n",
    "        ani.save(save_path, writer='ffmpeg', fps=1000/interval)\n",
    "        print(f\"Saved animation as {save_path}\")\n",
    "\n",
    "    plt.close(fig)\n",
    "    return HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtK4jQJoN29w"
   },
   "outputs": [],
   "source": [
    "# %% ----- 10. Run 2D Animation (FIXED) -----\n",
    "# This call now uses the correct unscaled validation variables saved in Cell 4.\n",
    "\n",
    "animation = animate_trajectory_pytorch_2d(\n",
    "    model,                      # The trained PyTorch model\n",
    "    X_val_list,                 # List of SCALED inputs [s, a_f, a_l]\n",
    "    X_s_val_unscaled_viz,       # UNCALED, centered initial states\n",
    "    y_val_unscaled_viz,       # UNSCALED, centered true deltas\n",
    "    scaler_y,                   # The scaler for deltas\n",
    "    start_idx=0,\n",
    "    steps=100,\n",
    "    interval=100\n",
    ")\n",
    "animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjwRKAcVlRdz"
   },
   "outputs": [],
   "source": [
    "# %% ----- 11. Multi-View Visualization (10 Samples - FIXED) -----\n",
    "# This cell was broken in the original notebook.\n",
    "# This version is fixed to use the correct data variables and PyTorch prediction.\n",
    "\n",
    "print(\"\\nCreating 10 sample predictions for multi-view visualization...\")\n",
    "\n",
    "num_samples_to_plot = 10\n",
    "\n",
    "if len(X_s_val_scaled) < num_samples_to_plot:\n",
    "    print(f\"Warning: Only {len(X_s_val_scaled)} samples in validation set. Using all.\")\n",
    "    num_samples_to_plot = len(X_s_val_scaled)\n",
    "    sample_indices = np.arange(num_samples_to_plot)\n",
    "else:\n",
    "    sample_indices = np.random.choice(len(X_s_val_scaled), num_samples_to_plot, replace=False)\n",
    "\n",
    "# Get scaled input data (batch of 10)\n",
    "s_initial_batch_scaled = X_val_list[0][sample_indices]\n",
    "a_force_batch_scaled = X_val_list[1][sample_indices]\n",
    "a_link_id_batch = X_val_list[2][sample_indices]\n",
    "\n",
    "# Get unscaled initial state and true DELTA for plotting (from Cell 4 fix)\n",
    "all_s_initial_original = X_s_val_unscaled_viz[sample_indices]\n",
    "all_y_true_delta_original = y_val_unscaled_viz[sample_indices]\n",
    "\n",
    "# --- Run Prediction ---\n",
    "print(\"Running prediction...\")\n",
    "start_pred_time = time.time()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    s_tensor = torch.tensor(s_initial_batch_scaled, dtype=torch.float32).to(device)\n",
    "    f_tensor = torch.tensor(a_force_batch_scaled, dtype=torch.float32).to(device)\n",
    "    l_tensor = torch.tensor(a_link_id_batch, dtype=torch.long).squeeze(-1).to(device)\n",
    "    \n",
    "    predicted_delta_scaled_tensor = model(s_tensor, f_tensor, l_tensor)\n",
    "    predicted_delta_scaled = predicted_delta_scaled_tensor.cpu().numpy()\n",
    "end_pred_time = time.time()\n",
    "print(f\"Prediction complete in {end_pred_time - start_pred_time:.2f} seconds.\")\n",
    "\n",
    "# --- Inverse Transform (Un-scaling) ---\n",
    "all_delta_pred_original = scaler_y.inverse_transform(\n",
    "    predicted_delta_scaled.reshape(-1, state_dims)\n",
    ").reshape(predicted_delta_scaled.shape)\n",
    "\n",
    "# Calculate predicted NEXT STATE\n",
    "all_next_state_pred_original = all_s_initial_original + all_delta_pred_original\n",
    "# Calculate true NEXT STATE\n",
    "all_next_state_true_original = all_s_initial_original + all_y_true_delta_original\n",
    "\n",
    "# Unscale actions (using the correct variable from Cell 4)\n",
    "all_a_force_original = X_a_force_val_unscaled_viz[sample_indices]\n",
    "all_a_link_id_original = X_a_link_id_val_viz[sample_indices].squeeze()\n",
    "\n",
    "if np.any(np.isnan(all_next_state_pred_original)) or np.any(np.isinf(all_next_state_pred_original)):\n",
    "    print(\"\\nWARNING: Model predictions contain NaN or Inf values!\")\n",
    "\n",
    "# --- Multi-View Plot Grid (Matplotlib code is identical) ---\n",
    "print(\"Visualizing 10 generated next states in multiple views...\")\n",
    "\n",
    "fig = plt.figure(figsize=(24, 20))\n",
    "\n",
    "def plot_rope_3d(ax, rope_coords, label, color, style='-o'):\n",
    "    if np.any(np.isnan(rope_coords)) or np.any(np.isinf(rope_coords)): return False\n",
    "    ax.plot(rope_coords[:, 0], rope_coords[:, 1], rope_coords[:, 2], style, label=label, color=color, markersize=2, lw=1.5)\n",
    "    return True\n",
    "\n",
    "def plot_rope_2d(ax, rope_coords, x_idx, y_idx, label, color, style='-o'):\n",
    "    if np.any(np.isnan(rope_coords)) or np.any(np.isinf(rope_coords)): return False\n",
    "    ax.plot(rope_coords[:, x_idx], rope_coords[:, y_idx], style, label=label, color=color, markersize=2, lw=1.5)\n",
    "    return True\n",
    "\n",
    "typical_force_magnitude = np.linalg.norm(scaler_a_force.scale_)\n",
    "if typical_force_magnitude < 1e-6: typical_force_magnitude = 1.0\n",
    "\n",
    "for i in range(num_samples_to_plot):\n",
    "    row_idx = i // 2\n",
    "    col_offset = (i % 2) * 3\n",
    "\n",
    "    ax_3d = fig.add_subplot(5, 6, row_idx * 6 + col_offset + 1, projection='3d')\n",
    "    ax_xy = fig.add_subplot(5, 6, row_idx * 6 + col_offset + 2)\n",
    "    ax_yz = fig.add_subplot(5, 6, row_idx * 6 + col_offset + 3)\n",
    "\n",
    "    s_initial = all_s_initial_original[i]\n",
    "    next_state_true = all_next_state_true_original[i]\n",
    "    next_state_pred = all_next_state_pred_original[i]\n",
    "    a_force_original = all_a_force_original[i]\n",
    "    a_link_id_original = all_a_link_id_original[i]\n",
    "\n",
    "    all_coords = np.concatenate([s_initial, next_state_true, next_state_pred], axis=0)\n",
    "    min_vals = np.nanmin(all_coords, axis=0)\n",
    "    max_vals = np.nanmax(all_coords, axis=0)\n",
    "    if np.any(np.isnan(min_vals)) or np.any(np.isnan(max_vals)):\n",
    "        min_vals = np.array([-1.0, -1.0, -1.0]); max_vals = np.array([ 1.0,  1.0,  1.0])\n",
    "\n",
    "    center = (max_vals + min_vals) / 2.0\n",
    "    span = (max_vals - min_vals)\n",
    "    plot_radius = np.nanmax(span) * 0.6\n",
    "    if plot_radius < 1e-6: plot_radius = 1.0\n",
    "    lims = [(c - plot_radius, c + plot_radius) for c in center]\n",
    "\n",
    "    base_arrow_length = plot_radius * 0.3\n",
    "    force_to_visual_scale = base_arrow_length / (typical_force_magnitude + 1e-6)\n",
    "\n",
    "    plot_rope_3d(ax_3d, s_initial, 'Initial', 'gray', style='--')\n",
    "    plot_rope_3d(ax_3d, next_state_true, 'True', 'blue')\n",
    "    plot_3d_success = plot_rope_3d(ax_3d, next_state_pred, 'Pred', 'red')\n",
    "    ax_3d.set_title(f'Sample {sample_indices[i]} (3D)')\n",
    "    ax_3d.set_xlabel('X'); ax_3d.set_ylabel('Y'); ax_3d.set_zlabel('Z')\n",
    "    ax_3d.set_xlim(lims[0]); ax_3d.set_ylim(lims[1]); ax_3d.set_zlim(lims[2])\n",
    "    try: ax_3d.set_aspect('equal')\n",
    "    except NotImplementedError: pass\n",
    "\n",
    "    plot_rope_2d(ax_xy, s_initial, 0, 1, 'Initial', 'gray', style='--')\n",
    "    plot_rope_2d(ax_xy, next_state_true, 0, 1, 'True', 'blue')\n",
    "    plot_xy_success = plot_rope_2d(ax_xy, next_state_pred, 0, 1, 'Pred', 'red')\n",
    "    ax_xy.set_title(f'Sample {sample_indices[i]} (XY)')\n",
    "    ax_xy.set_xlabel('X'); ax_xy.set_ylabel('Y')\n",
    "    ax_xy.set_xlim(lims[0]); ax_xy.set_ylim(lims[1])\n",
    "    ax_xy.grid(True); ax_xy.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    plot_rope_2d(ax_yz, s_initial, 1, 2, 'Initial', 'gray', style='--')\n",
    "    plot_rope_2d(ax_yz, next_state_true, 1, 2, 'True', 'blue')\n",
    "    plot_yz_success = plot_rope_2d(ax_yz, next_state_pred, 1, 2, 'Pred', 'red')\n",
    "    ax_yz.set_title(f'Sample {sample_indices[i]} (YZ)')\n",
    "    ax_yz.set_xlabel('Y'); ax_yz.set_ylabel('Z')\n",
    "    ax_yz.set_xlim(lims[1]); ax_yz.set_ylim(lims[2])\n",
    "    ax_yz.grid(True); ax_yz.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    start_point = s_initial[a_link_id_original]\n",
    "    if not (np.any(np.isnan(start_point)) or np.any(np.isinf(start_point))):\n",
    "        Fx = a_force_original[0] * force_to_visual_scale\n",
    "        Fy = a_force_original[1] * force_to_visual_scale\n",
    "        Fz = a_force_original[2] * force_to_visual_scale\n",
    "        ax_3d.quiver(start_point[0], start_point[1], start_point[2], Fx, Fy, Fz,\n",
    "                     color='magenta', length=np.sqrt(Fx**2+Fy**2+Fz**2), normalize=True,\n",
    "                     label=f'Force (L{a_link_id_original})', zorder=5)\n",
    "        ax_3d.scatter(start_point[0], start_point[1], start_point[2],\n",
    "                      color='magenta', s=30, edgecolors='black', alpha=0.8, zorder=10)\n",
    "\n",
    "        ax_xy.quiver(start_point[0], start_point[1], Fx, Fy, color='magenta',\n",
    "                     scale=1, scale_units='xy', angles='xy', zorder=5)\n",
    "        ax_xy.scatter(start_point[0], start_point[1], color='magenta', s=30,\n",
    "                      edgecolors='black', alpha=0.8, zorder=10)\n",
    "\n",
    "        ax_yz.quiver(start_point[1], start_point[2], Fy, Fz, color='magenta',\n",
    "                     scale=1, scale_units='xy', angles='xy', zorder=5)\n",
    "        ax_yz.scatter(start_point[1], start_point[2], color='magenta', s=30,\n",
    "                      edgecolors='black', alpha=0.8, zorder=10)\n",
    "\n",
    "    final_mse = np.nanmean((next_state_true - next_state_pred)**2)\n",
    "    ax_3d.set_title(f'Sample {sample_indices[i]} (3D)\\nMSE: {final_mse:.6f}')\n",
    "\n",
    "first_ax_with_legend = None\n",
    "for k in range(num_samples_to_plot * 3):\n",
    "    try:\n",
    "        ax = fig.axes[k]\n",
    "        if ax.has_data():\n",
    "             first_ax_with_legend = ax\n",
    "             break\n",
    "    except IndexError: break\n",
    "if first_ax_with_legend:\n",
    "    first_ax_with_legend.legend(loc='center left', bbox_to_anchor=(1.1, 0.5), fontsize='small')\n",
    "\n",
    "for j in range(num_samples_to_plot, 10):\n",
    "     row_idx = j // 2\n",
    "     col_offset = (j % 2) * 3\n",
    "     for k in range(3):\n",
    "         try:\n",
    "             ax_to_hide = fig.axes[row_idx * 6 + col_offset + k]\n",
    "             ax_to_hide.axis('off')\n",
    "         except IndexError: pass\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.95, 1])\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch)",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}